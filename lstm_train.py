import numpy as np
import pandas as pd
import torch as th
import os
from typing import Callable, Dict, Any
from stable_baselines3 import SAC
from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.utils import set_random_seed
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
from stable_baselines3.common.policies import ActorCriticPolicy
import gymnasium as gym

# Import custom modules
from featuresNew import add_features_lstm
from LSTM_bnn_policy import LSTM_BNN_Policy
from MarginForexEnv import MarginForexEnv

# -------------------------------
# ğŸ”§ Step 0: è®¾ç½®éšæœºç§å­
# -------------------------------

SEED = 42
set_random_seed(SEED, using_cuda=True)
np.random.seed(SEED)
th.manual_seed(SEED)
if th.cuda.is_available():
    th.cuda.manual_seed_all(SEED)

print("ğŸš€ å¼€å§‹è®­ç»ƒ LSTM-BNN-SAC å¤–æ±‡äº¤æ˜“æ¨¡å‹")
print("=" * 60)

# -------------------------------
# ğŸ“‚ Step 1: åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
# -------------------------------

print("ğŸ“‚ åŠ è½½æ•°æ®...")
df = pd.read_csv('./data/2024min1.csv', index_col=0, parse_dates=True)

# é™åˆ¶æ•°æ®é‡ï¼ˆé¿å…å†…å­˜é—®é¢˜ï¼‰
data_size = min(10000, len(df))
df = df.iloc[-data_size:].copy()
df.reset_index(inplace=True)
df.rename(columns={'index': 'timestamp'}, inplace=True)  # ç¡®ä¿æœ‰æ—¶é—´åˆ—

print(f"   åŸå§‹æ•°æ®: {len(df):,} è¡Œ")

# -------------------------------
# ğŸ”§ Step 2: ç‰¹å¾å·¥ç¨‹ï¼ˆç¡®ä¿åŒ…å«å¿…è¦å­—æ®µï¼‰
# -------------------------------

print("ğŸ”§ ç‰¹å¾å·¥ç¨‹...")


df = add_features_lstm(df)
print(f"   å¤„ç†å: {len(df):,} è¡Œ, {len(df.columns)} åˆ—")

# -------------------------------
# ğŸ”€ Step 3: æ—¶åºåˆ†å‰²
# -------------------------------

def create_data_splits(df: pd.DataFrame, train_ratio: float = 0.7, val_ratio: float = 0.15):
    n = len(df)
    train_end = int(n * train_ratio)
    val_end = int(n * (train_ratio + val_ratio))
    
    df_train = df.iloc[:train_end].copy()
    df_val = df.iloc[train_end:val_end].copy()
    df_test = df.iloc[val_end:].copy()
    
    print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
    print(f"   è®­ç»ƒé›†: {len(df_train):,} è¡Œ ({train_ratio*100:.0f}%)")
    print(f"   éªŒè¯é›†: {len(df_val):,} è¡Œ ({val_ratio*100:.0f}%)")
    print(f"   æµ‹è¯•é›†: {len(df_test):,} è¡Œ ({(1-train_ratio-val_ratio)*100:.0f}%)")
    
    return df_train, df_val, df_test

df_train, df_val, df_test = create_data_splits(df)

# -------------------------------
# ğŸ§ª Step 4: ç¯å¢ƒå®‰å…¨æ€§æµ‹è¯•
# -------------------------------

def test_environment_safety(env_class, df_sample: pd.DataFrame):
    print("ğŸ§ª å¼€å§‹ç¯å¢ƒå®‰å…¨æ€§æµ‹è¯•...")
    
    test_env = env_class(df_sample, max_position_ratio=0.3, lookback=60)
    obs, _ = test_env.reset()
    
    issues = []
    
    for i in range(min(100, len(df_sample) - test_env.lookback - 10)):
        action = test_env.action_space.sample()
        
        try:
            obs, reward, terminated, truncated, info = test_env.step(action)
            
            if np.any(np.isnan(obs)) or np.any(np.isinf(obs)):
                issues.append(f"æ­¥éª¤ {i}: è§‚æµ‹åŒ…å« NaN/Inf")
            if np.isnan(reward) or np.isinf(reward):
                issues.append(f"æ­¥éª¤ {i}: å¥–åŠ±ä¸º NaN/Inf: {reward}")
            if info['equity'] <= 0:
                issues.append(f"æ­¥éª¤ {i}: æƒç›Šä¸ºè´Ÿ: {info['equity']}")
                
            if terminated or truncated:
                break
                
        except Exception as e:
            issues.append(f"æ­¥éª¤ {i}: å¼‚å¸¸ {str(e)}")
            break
    
    if issues:
        print("âš ï¸ å‘ç°ç¯å¢ƒé—®é¢˜:")
        for issue in issues[:5]:
            print(f"   - {issue}")
        return False
    else:
        print("âœ… ç¯å¢ƒå®‰å…¨æ€§æµ‹è¯•é€šè¿‡!")
        return True

# MarginForexEnv is now imported at the top of the file

if not test_environment_safety(MarginForexEnv, df_train.iloc[:1000]):
    raise RuntimeError("ç¯å¢ƒæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ MarginForexEnv å®ç°")

# -------------------------------
# ğŸ—ï¸ Step 5: åˆ›å»ºè®­ç»ƒ/éªŒè¯ç¯å¢ƒ
# -------------------------------

print("ğŸ—ï¸ åˆ›å»ºè®­ç»ƒç¯å¢ƒ...")

train_env = MarginForexEnv(
    df=df_train,
    initial_balance=100_000,
    leverage=100,
    max_position_ratio=0.5,
    cost_ratio=7e-5,
    lookback=60,
    stop_out_level=50.0,
)
train_env = Monitor(train_env, filename="logs/train_monitor")

eval_env = MarginForexEnv(
    df=df_val,
    initial_balance=100_000,
    leverage=100,
    max_position_ratio=0.5,
    cost_ratio=7e-5,
    lookback=60,
    stop_out_level=50.0,
)
eval_env = Monitor(eval_env, filename="logs/eval_monitor")

# -------------------------------
# ğŸ”„ Step 6: å‘é‡åŒ– + å½’ä¸€åŒ–
# -------------------------------

# LSTM è¦æ±‚åºåˆ—è¾“å…¥ï¼Œä½¿ç”¨ DummyVecEnv åŒ…è£…
train_vec_env = DummyVecEnv([lambda: train_env])

# âœ… é‡è¦ï¼šVecNormalize ä¸ä¼šæ‰“ä¹±åºåˆ—ç»´åº¦
# æˆ‘ä»¬åªå½’ä¸€åŒ–è§‚æµ‹ä¸­çš„ç‰¹å¾ï¼Œä¸å½’ä¸€åŒ–æ•´ä¸ªåºåˆ—ç»“æ„
train_vec_env = VecNormalize(
    train_vec_env,
    norm_obs=True,
    norm_reward=True,
    clip_obs=10.0,
    clip_reward=10.0,
    gamma=0.99,
    epsilon=1e-8,
)

eval_vec_env = DummyVecEnv([lambda: eval_env])
eval_vec_env = VecNormalize(
    eval_vec_env,
    norm_obs=True,
    norm_reward=False,
    training=False,
    clip_obs=10.0,
    epsilon=1e-8,
)

# -------------------------------
# ğŸ§  Step 7: è‡ªå®šä¹‰ LSTM-BNN ç»„ä»¶
# -------------------------------


# -------------------------------
# âš™ï¸ Step 8: åˆ›å»º SAC æ¨¡å‹
# -------------------------------

print("ğŸ¤– åˆ›å»º SAC æ¨¡å‹ï¼ˆé€‚é… LSTM-BNNï¼‰...")

model = SAC(
    policy=LSTM_BNN_Policy,
    env=train_vec_env,
    verbose=1,
    tensorboard_log="./sac_lstm_bnn_log/",
    learning_rate=3e-4,
    batch_size=256,
    buffer_size=100_000,
    learning_starts=5000,
    tau=0.005,
    gamma=0.99,
    train_freq=1,
    gradient_steps=1,
    device="cuda" if th.cuda.is_available() else "cpu",
    seed=SEED,
    policy_kwargs={
        'log_std_init': -2.0,
        'net_arch': dict(pi=[256, 256], qf=[256, 256]),
        'share_features_extractor': False,
    }
)

print(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {model.device}")
total_params = sum(p.numel() for p in model.policy.parameters())
print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {total_params:,}")

# -------------------------------
# ğŸ“ˆ Step 9: å›è°ƒå‡½æ•°
# -------------------------------

os.makedirs("logs", exist_ok=True)
os.makedirs("checkpoints", exist_ok=True)

eval_callback = EvalCallback(
    eval_vec_env,
    best_model_save_path="./logs/",
    log_path="./logs/",
    eval_freq=10_000,
    deterministic=True,
    n_eval_episodes=3,
    verbose=1,
)

checkpoint_callback = CheckpointCallback(
    save_freq=20_000,
    save_path="./checkpoints/",
    name_prefix="lstm_bnn_sac",
    verbose=1,
)

# -------------------------------
# ğŸš€ Step 10: å¼€å§‹è®­ç»ƒ
# -------------------------------

total_timesteps = 50_000
print(f"\nğŸ‹ï¸ å¼€å§‹è®­ç»ƒ {total_timesteps:,} æ­¥...")

try:
    model.learn(
        total_timesteps=total_timesteps,
        callback=[eval_callback, checkpoint_callback],
        tb_log_name=f"LSTM_BNN_SAC_{SEED}",
        progress_bar=True,
    )
    print("âœ… è®­ç»ƒæˆåŠŸå®Œæˆï¼")

except KeyboardInterrupt:
    print("\nâš ï¸ è®­ç»ƒè¢«ä¸­æ–­ï¼Œä¿å­˜å½“å‰æ¨¡å‹...")
except Exception as e:
    print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
    import traceback
    traceback.print_exc()

# -------------------------------
# ğŸ’¾ Step 11: ä¿å­˜æ¨¡å‹
# -------------------------------

print("ğŸ’¾ ä¿å­˜æœ€ç»ˆæ¨¡å‹...")
model.save("lstm_bnn_sac_forex_final")
train_vec_env.save("train_vec_normalize.pkl")
eval_vec_env.save("eval_vec_normalize.pkl")

df_test.to_csv("data/test_data.csv", index=False)
print("âœ… æ‰€æœ‰æ–‡ä»¶ä¿å­˜å®Œæˆï¼")

# -------------------------------
# ğŸ“Š æç¤ºä¿¡æ¯
# -------------------------------

print("\n" + "=" * 60)
print("ğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆï¼")
print("=" * 60)
print("ğŸ“Š æŸ¥çœ‹æ—¥å¿—:")
print("   tensorboard --logdir=./sac_lstm_bnn_log/")
print("ğŸš€ è¯„ä¼°æ¨¡å‹:")
print("   python evaluate.py")
print("=" * 60)