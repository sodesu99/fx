# %%
import numpy as np
import pandas as pd
import torch as th
import os
from typing import Callable
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, StopTrainingOnNoModelImprovement
from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.utils import set_random_seed
from forex_envNew import ForexEnv
from bnn_policy import BNNActorCriticPolicy

# âœ… ä¿®å¤ï¼šè®¾ç½®éšæœºç§å­
SEED = 42
set_random_seed(SEED, using_cuda=True)
np.random.seed(SEED)
th.manual_seed(SEED)


# %%


# %%

def create_data_splits(df: pd.DataFrame, train_ratio: float = 0.7, val_ratio: float = 0.15):
    """
    âœ… æ–°å¢ï¼šæ­£ç¡®çš„æ—¶åºæ•°æ®åˆ†å‰²ï¼Œé¿å…æ•°æ®æ³„éœ²
    """
    n = len(df)
    train_end = int(n * train_ratio)
    val_end = int(n * (train_ratio + val_ratio))
    
    df_train = df.iloc[:train_end].copy()
    df_val = df.iloc[train_end:val_end].copy()
    df_test = df.iloc[val_end:].copy()
    
    print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
    print(f"   è®­ç»ƒé›†: {len(df_train):,} è¡Œ ({train_ratio*100:.0f}%)")
    print(f"   éªŒè¯é›†: {len(df_val):,} è¡Œ ({val_ratio*100:.0f}%)")
    print(f"   æµ‹è¯•é›†: {len(df_test):,} è¡Œ ({(1-train_ratio-val_ratio)*100:.0f}%)")
    
    return df_train, df_val, df_test


# %%

# âœ… ä¸»ç¨‹åºå¼€å§‹
print("ğŸš€ å¼€å§‹è®­ç»ƒ BNN-PPO å¤–æ±‡äº¤æ˜“æ¨¡å‹")
print("=" * 50)

# 1. åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
print("ğŸ“‚ åŠ è½½æ•°æ®...")
df = pd.read_csv('./data/2024min1.csv', index_col=0, parse_dates=True)

# âœ… æ›´ä¿å®ˆçš„æ•°æ®ä½¿ç”¨ç­–ç•¥
data_size = min(10000, len(df))  # é™åˆ¶æ•°æ®å¤§å°ï¼Œé¿å…å†…å­˜é—®é¢˜
df = df.iloc[-data_size:].copy()  # ä½¿ç”¨æœ€æ–°æ•°æ®
df.reset_index(inplace=True)

print(f"   åŸå§‹æ•°æ®: {len(df):,} è¡Œ")

# 2. ç‰¹å¾å·¥ç¨‹
print("ğŸ”§ ç‰¹å¾å·¥ç¨‹...")
from featuresNew import add_features
df = add_features(df)
print(f"   å¤„ç†å: {len(df):,} è¡Œ, {len(df.columns)} åˆ—")

# âœ… 3. æ­£ç¡®çš„æ•°æ®åˆ†å‰²
df_train, df_val, df_test = create_data_splits(df)



# %%

def create_learning_rate_schedule(initial_lr: float = 3e-4, warmup_steps: int = 10000, decay_factor: float = 0.5, total_timesteps = 100000) -> Callable[[float], float]:
    """
    âœ… æ”¹è¿›ï¼šå­¦ä¹ ç‡è°ƒåº¦å™¨
    """
    def schedule(progress_remaining: float) -> float:
        # è®¡ç®—å½“å‰æ­¥æ•°
        current_step = int((1 - progress_remaining) * total_timesteps)
        
        # é¢„çƒ­é˜¶æ®µ
        if current_step < warmup_steps:
            return initial_lr * (current_step / warmup_steps)
        
        # ä½™å¼¦é€€ç«
        decay_progress = (current_step - warmup_steps) / (total_timesteps - warmup_steps)
        return initial_lr * (decay_factor + (1 - decay_factor) * 0.5 * (1 + np.cos(np.pi * decay_progress)))
    
    return schedule

def test_environment_safety(env_class, df_sample: pd.DataFrame):
    """
    âœ… æ–°å¢ï¼šç¯å¢ƒå®‰å…¨æ€§æµ‹è¯•
    """
    print("ğŸ§ª å¼€å§‹ç¯å¢ƒå®‰å…¨æ€§æµ‹è¯•...")
    
    test_env = env_class(df_sample, max_position=0.3)
    obs, _ = test_env.reset()
    
    issues = []
    
    for i in range(min(100, len(df_sample) - test_env.lookback - 10)):
        action = test_env.action_space.sample()
        
        try:
            obs, reward, terminated, truncated, info = test_env.step(action)
            
            # æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
            if np.any(np.isnan(obs)) or np.any(np.isinf(obs)):
                issues.append(f"æ­¥éª¤ {i}: è§‚æµ‹åŒ…å« NaN/Inf")
            
            if np.isnan(reward) or np.isinf(reward):
                issues.append(f"æ­¥éª¤ {i}: å¥–åŠ±ä¸º NaN/Inf: {reward}")
                
            if info['net_worth'] <= 0:
                issues.append(f"æ­¥éª¤ {i}: å‡€å€¼ä¸ºè´Ÿæˆ–é›¶: {info['net_worth']}")
                
            if terminated or truncated:
                break
                
        except Exception as e:
            issues.append(f"æ­¥éª¤ {i}: å¼‚å¸¸ {str(e)}")
            break
    
    if issues:
        print("âš ï¸ å‘ç°ç¯å¢ƒé—®é¢˜:")
        for issue in issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
            print(f"   - {issue}")
        if len(issues) > 5:
            print(f"   - ... è¿˜æœ‰ {len(issues) - 5} ä¸ªé—®é¢˜")
        return False
    else:
        print("âœ… ç¯å¢ƒå®‰å…¨æ€§æµ‹è¯•é€šè¿‡!")
        return True

# %%

# 4. ç¯å¢ƒå®‰å…¨æ€§æµ‹è¯•
if not test_environment_safety(ForexEnv, df_train.iloc[:5000]):
    print("âŒ ç¯å¢ƒæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ")
    exit(1)

# 5. åˆ›å»ºè®­ç»ƒç¯å¢ƒ
print("ğŸ—ï¸ åˆ›å»ºè®­ç»ƒç¯å¢ƒ...")
train_env = ForexEnv(
    df_train, 
    max_position=0.25,  # âœ… æ›´ä¿å®ˆçš„ä»“ä½é™åˆ¶
    cost_ratio=0.0002,  # âœ… æ›´ç°å®çš„äº¤æ˜“æˆæœ¬
    trade_penalty=0.0005,  # âœ… å‡å°‘è¿‡åº¦äº¤æ˜“
)
train_env = Monitor(train_env, filename="logs/train_monitor.csv")

# 6. åˆ›å»ºéªŒè¯ç¯å¢ƒï¼ˆç‹¬ç«‹æ•°æ®ï¼‰
print("ğŸ” åˆ›å»ºéªŒè¯ç¯å¢ƒ...")
eval_env = ForexEnv(
    df_val, 
    max_position=0.25,
    cost_ratio=0.0002,
    trade_penalty=0.0005,
)
eval_env = Monitor(eval_env, filename="logs/eval_monitor.csv")

# %%

# 7. å‘é‡åŒ–ç¯å¢ƒ
train_vec_env = DummyVecEnv([lambda: train_env])
train_vec_env = VecNormalize(
    train_vec_env,
    norm_obs=True,
    norm_reward=True,
    gamma=0.99,
    clip_obs=10.0,
    epsilon=1e-8,  # âœ… æ•°å€¼ç¨³å®šæ€§
)

eval_vec_env = DummyVecEnv([lambda: eval_env])
eval_vec_env = VecNormalize(
    eval_vec_env,
    norm_obs=True,
    norm_reward=False,  # âœ… è¯„ä¼°æ—¶ä¸æ ‡å‡†åŒ–å¥–åŠ±
    gamma=0.99,
    clip_obs=10.0,
    training=False,  # âœ… è¯„ä¼°ç¯å¢ƒä¸æ›´æ–°ç»Ÿè®¡é‡
    epsilon=1e-8,
)

# %%

# âœ… 8. è®¾ç½®è®­ç»ƒå‚æ•°
total_timesteps = 10000  # å¢åŠ è®­ç»ƒæ­¥æ•°
print(f"ğŸ¯ æ€»è®­ç»ƒæ­¥æ•°: {total_timesteps:,}")

# 9. åˆ›å»ºå›è°ƒå‡½æ•°
os.makedirs("logs", exist_ok=True)
os.makedirs("checkpoints", exist_ok=True)

# æå‰åœæ­¢
stop_callback = StopTrainingOnNoModelImprovement(
    max_no_improvement_evals=5,  # âœ… æ›´å®½æ¾çš„åœæ­¢æ¡ä»¶
    min_evals=10,
    verbose=1
)

# è¯„ä¼°å›è°ƒ
eval_callback = EvalCallback(
    eval_vec_env,
    best_model_save_path="./logs/",
    log_path="./logs/",
    eval_freq=15000,  # âœ… æ›´é¢‘ç¹çš„è¯„ä¼°
    deterministic=True,
    callback_after_eval=stop_callback,
    n_eval_episodes=3,  # âœ… å¤šè½®è¯„ä¼°æ±‚å¹³å‡
    verbose=1,
)

# æ£€æŸ¥ç‚¹ä¿å­˜
checkpoint_callback = CheckpointCallback(
    save_freq=30000,
    save_path="./checkpoints/",
    name_prefix="bnn_ppo_forex",
    verbose=1,
)


# %%

# âœ… 10. åˆ›å»ºæ¨¡å‹ï¼ˆä¼˜åŒ–è¶…å‚æ•°ï¼‰
print("ğŸ¤– åˆ›å»º PPO æ¨¡å‹...")

model = PPO(
    policy=BNNActorCriticPolicy,
    env=train_vec_env,
    verbose=1,
    tensorboard_log="./bnn_ppo_log/",
    learning_rate=create_learning_rate_schedule(2e-4, 15000, 0.3, total_timesteps = total_timesteps),  # âœ… æ›´ä½å­¦ä¹ ç‡
    batch_size=512,        # âœ… å¢å¤§æ‰¹æ¬¡
    n_steps=2048,          # âœ… å¢å¤§æ­¥æ•°
    gamma=0.995,           # âœ… æ›´é‡è§†é•¿æœŸå¥–åŠ±
    gae_lambda=0.95,       # âœ… å¹³è¡¡åå·®å’Œæ–¹å·®
    ent_coef=0.005,        # âœ… å‡å°‘ç†µæ­£åˆ™åŒ–
    clip_range=0.15,       # âœ… æ›´ä¿å®ˆçš„è£å‰ª
    n_epochs=8,            # âœ… å¢åŠ è®­ç»ƒè½®æ•°
    max_grad_norm=1.0,     # âœ… æ¢¯åº¦è£å‰ª
    vf_coef=0.5,           # âœ… ä»·å€¼å‡½æ•°æƒé‡
    target_kl=0.02,        # âœ… æ›´ä¸¥æ ¼çš„KLæ•£åº¦é™åˆ¶
    device="cuda" if th.cuda.is_available() else "cpu",
    seed=SEED,
    policy_kwargs={
        'log_std_init': -2.0,      # âœ… æ›´ä¿å®ˆçš„ç­–ç•¥åˆå§‹åŒ–
        'ortho_init': True,
        'activation_fn': th.nn.ReLU,
        'net_arch': [dict(pi=[256, 256, 128], vf=[256, 256, 128])],  # âœ… ä¼˜åŒ–ç½‘ç»œç»“æ„
        'share_features_extractor': False,  # âœ… ç­–ç•¥å’Œä»·å€¼ç½‘ç»œç‹¬ç«‹ç‰¹å¾æå–
    }
)

print(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {model.device}")
print("ğŸ‹ï¸ æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
total_params = sum(p.numel() for p in model.policy.parameters())
trainable_params = sum(p.numel() for p in model.policy.parameters() if p.requires_grad)
print(f"   æ€»å‚æ•°: {total_params:,}")
print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

# %%

# âœ… 11. å¼€å§‹è®­ç»ƒ
print("\n" + "=" * 50)
print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
print("=" * 50)

try:
    model.learn(
        total_timesteps=total_timesteps,
        callback=[eval_callback, checkpoint_callback],
        tb_log_name=f"BNN_PPO_{SEED}",
        progress_bar=True,
        reset_num_timesteps=False
    )
    
    print("âœ… è®­ç»ƒæˆåŠŸå®Œæˆ!")
    
except KeyboardInterrupt:
    print("\nâš ï¸ è®­ç»ƒè¢«ä¸­æ–­ï¼Œä¿å­˜å½“å‰æ¨¡å‹...")
    
except Exception as e:
    print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
    import traceback
    traceback.print_exc()

# %%

# 12. ä¿å­˜æ¨¡å‹å’Œç¯å¢ƒå‚æ•°
print("ğŸ’¾ ä¿å­˜æ¨¡å‹...")
model.save("bnn_ppo_forex_final")
train_vec_env.save("train_vec_normalize.pkl")
eval_vec_env.save("eval_vec_normalize.pkl")

# âœ… 13. ä¿å­˜æµ‹è¯•æ•°æ®ï¼ˆç”¨äºåç»­è¯„ä¼°ï¼‰
print("ğŸ“Š ä¿å­˜æµ‹è¯•æ•°æ®...")
df_test.to_csv("data/test_data.csv")

print("\n" + "=" * 50)
print("âœ… è®­ç»ƒæµç¨‹å®Œæˆ!")
print("=" * 50)
print("ğŸ“Š æŸ¥çœ‹è®­ç»ƒæ—¥å¿—:")
print(f"   TensorBoard: tensorboard --logdir=./bnn_ppo_log/")
print(f"   ç›‘æ§æ–‡ä»¶: logs/train_monitor.csv")
print("ğŸš€ è¿è¡Œè¯„ä¼°:")
print(f"   python evaluate.py")
print("=" * 50)

# %%

# åœ¨ evaluate.py æœ«å°¾æ·»åŠ æ­¤å‡½æ•°
def plot_trading_signals(df,  save_path="trading_signals.png"):
    """
    ç»˜åˆ¶äº¤æ˜“ä¿¡å·å åŠ åœ¨ä»·æ ¼å›¾ä¸Š
    """
    import matplotlib.pyplot as plt
    from matplotlib.patches import Rectangle

    fig, ax1 = plt.subplots(figsize=(16, 8))


    # 1. ç»˜åˆ¶ä»·æ ¼æ›²çº¿
    ax1.plot(df['timestamp'], df['close'], label='EUR/USD Price', color='red', alpha=0.9, linewidth=1)

    # 4. è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
    ax1.set_title('EUR/USD Trading Signals with PPO + BNN Strategy', fontsize=16)
    ax1.set_xlabel('Time Index')
    ax1.set_ylabel('Price', fontsize=12)
    ax1.legend(loc='upper left')
    ax1.grid(True, alpha=0.3)

    fig, ax2 = plt.subplots(figsize=(16, 8))


    # 1. RCIæ›²çº¿
    ax2.plot(df['timestamp'], df['RCI21'], label='RCI21', color='blue', alpha=0.9, linewidth=1)


    # 4. è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
    ax2.set_title('EUR/USD Trading Signals with PPO + BNN Strategy', fontsize=16)
    ax2.set_ylabel('RCI21', fontsize=12)
    ax2.legend(loc='upper left')
    ax2.grid(True, alpha=0.3)

    ax3 = ax1.twinx()
    ax3.plot(df['timestamp'], df['RCI21'], label='RCI21', color='blue', alpha=0.9, linewidth=1)


    # 4. è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
    ax3.set_ylabel('RCI21', fontsize=12)
    ax3.legend()
    ax3.grid(True, alpha=0.3)

    # 5. ä¿å­˜å¹¶æ˜¾ç¤ºå›¾è¡¨
    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    plt.show()

    print(f"âœ… äº¤æ˜“ä¿¡å·å›¾å·²ä¿å­˜: {save_path}")



# %%


# %%
plot_trading_signals(df_val)


